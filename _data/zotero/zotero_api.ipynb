{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abff4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Preview first few publications\n",
    "print(\"üìö Preview of first 5 publications:\\n\")\n",
    "for i, pub in enumerate(filtered_publications[:5], 1):\n",
    "    print(f\"{i}. {pub['title']}\")\n",
    "    print(f\"   Authors: {pub['creators']}\")\n",
    "    print(f\"   Year: {pub['year']}, Region: {pub['region']}\")\n",
    "    if pub['doi']:\n",
    "        print(f\"   DOI: {pub['doi']}\")\n",
    "    if pub['url']:\n",
    "        print(f\"   URL: {pub['url']}\")\n",
    "    print()\n",
    "\n",
    "# Optional: Show a sample YAML entry\n",
    "print(\"üìã Sample YAML entry (how it will appear in Jekyll):\")\n",
    "print(yaml.dump([filtered_publications[0]], default_flow_style=False, allow_unicode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68aee23",
   "metadata": {},
   "source": [
    "## Step 6: Deploy to GitHub Repository\n",
    "\n",
    "**Instructions to integrate with your GitHub Pages site:**\n",
    "\n",
    "1. **Copy the YAML file to your repo:**\n",
    "   - Take the file `filtered_pifsc_publications.yml` generated above\n",
    "   - Place it in: `_data/filtered_pifsc_publications.yml` in your GitHub repository\n",
    "   - (Create the `_data` folder if it doesn't exist)\n",
    "\n",
    "2. **Verify the Jekyll template:**\n",
    "   - Your `_layouts/publications.html` expects the data at `site.data.filtered_pifsc_publications`\n",
    "   - The YAML file will be automatically loaded by Jekyll with this key\n",
    "\n",
    "3. **Push to GitHub:**\n",
    "   - Commit and push the updated `_data/filtered_pifsc_publications.yml` file\n",
    "   - GitHub Pages will rebuild and the publications will appear on your site\n",
    "\n",
    "4. **Testing locally (optional):**\n",
    "   - If you have Jekyll installed locally, run `bundle exec jekyll serve` in your repo root\n",
    "   - Navigate to the publications page to verify rendering\n",
    "\n",
    "**File mapping:**\n",
    "- Your repo should have this structure:\n",
    "  ```\n",
    "  esd-arp-resources/\n",
    "  ‚îú‚îÄ‚îÄ _data/\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ filtered_pifsc_publications.yml  ‚Üê Place the file here\n",
    "  ‚îú‚îÄ‚îÄ _layouts/\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ publications.html\n",
    "  ‚îî‚îÄ‚îÄ ... (other files)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV (for easy spreadsheet viewing/editing)\n",
    "csv_file = \"filtered_pifsc_publications.csv\"\n",
    "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    if filtered_publications:\n",
    "        writer = csv.DictWriter(f, fieldnames=filtered_publications[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(filtered_publications)\n",
    "print(f\"‚úì CSV export: {csv_file}\")\n",
    "\n",
    "# Export to JSON (for debugging/reference)\n",
    "json_file = \"filtered_pifsc_publications.json\"\n",
    "with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_publications, f, indent=2, ensure_ascii=False)\n",
    "print(f\"‚úì JSON export: {json_file}\")\n",
    "\n",
    "# Export to YAML (for Jekyll/GitHub Pages)\n",
    "# The Jekyll template expects: site.data.filtered_pifsc_publications\n",
    "yaml_file = \"filtered_pifsc_publications.yml\"\n",
    "with open(yaml_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    # YAML format for Jekyll _data folder\n",
    "    yaml.dump(filtered_publications, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n",
    "print(f\"‚úì YAML export: {yaml_file}\")\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  Total publications: {len(filtered_publications)}\")\n",
    "print(f\"  Years covered: {min(pub['year'] for pub in filtered_publications if pub['year'])} - {max(pub['year'] for pub in filtered_publications if pub['year'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee523b5",
   "metadata": {},
   "source": [
    "## Step 5: Export Data for GitHub Pages\n",
    "\n",
    "Generate outputs in multiple formats: CSV for spreadsheet, JSON for debugging, and YAML for Jekyll integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_publications = []\n",
    "duplicate_checker = set()\n",
    "\n",
    "for entry in all_items:\n",
    "    try:\n",
    "        data = entry.get(\"data\", {})\n",
    "        \n",
    "        # Extract fields\n",
    "        title = data.get(\"title\", \"\").strip()\n",
    "        if not title:\n",
    "            continue  # Skip entries without title\n",
    "        \n",
    "        # Check for duplicates (by title)\n",
    "        if title in duplicate_checker:\n",
    "            continue\n",
    "        duplicate_checker.add(title)\n",
    "        \n",
    "        # Build publication record\n",
    "        pub = {\n",
    "            \"title\": title,\n",
    "            \"creators\": clean_creators(data.get(\"creators\", [])),\n",
    "            \"year\": extract_year(data.get(\"date\", \"\")),\n",
    "            \"doi\": data.get(\"DOI\", \"\").strip() or None,\n",
    "            \"issn\": data.get(\"ISSN\", \"\").strip() or None,\n",
    "            \"url\": data.get(\"url\", \"\").strip() or None,\n",
    "            \"region\": assign_region(title),\n",
    "            # Additional useful fields\n",
    "            \"item_type\": data.get(\"itemType\", \"\"),\n",
    "            \"publication_title\": data.get(\"publicationTitle\", \"\").strip() or None,\n",
    "        }\n",
    "        \n",
    "        filtered_publications.append(pub)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing entry: {e}\")\n",
    "        continue\n",
    "\n",
    "# Sort by year (descending)\n",
    "filtered_publications.sort(key=lambda x: x[\"year\"] or 0, reverse=True)\n",
    "\n",
    "print(f\"\\n‚úì Processed {len(filtered_publications)} publications\")\n",
    "print(f\"‚úì Removed {len(all_items) - len(filtered_publications)} duplicates/invalid entries\")\n",
    "print(f\"\\nRegion distribution:\")\n",
    "regions = {}\n",
    "for pub in filtered_publications:\n",
    "    region = pub[\"region\"]\n",
    "    regions[region] = regions.get(region, 0) + 1\n",
    "for region, count in sorted(regions.items()):\n",
    "    print(f\"  {region}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3ac5a",
   "metadata": {},
   "source": [
    "## Step 4: Process and Filter Publications\n",
    "\n",
    "Extract relevant fields from each publication and apply cleaning/enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c14c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(date_str):\n",
    "    \"\"\"Extract 4-digit year from date string.\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    match = re.search(r\"\\b\\d{4}\\b\", str(date_str))\n",
    "    return int(match.group(0)) if match else None\n",
    "\n",
    "def assign_region(title):\n",
    "    \"\"\"Assign region based on publication title keywords.\"\"\"\n",
    "    if not title:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    # Hawaiian Archipelago keywords\n",
    "    if any(area in title_lower for area in ['hawai', 'hawaii', 'kahekili', 'maui', 'ahu', 'northwestern', 'papahƒÅnaumokuƒÅkea', 'kauai', 'oahu', 'big island']):\n",
    "        return 'Hawaiian Archipelago'\n",
    "    \n",
    "    # American Samoa keywords\n",
    "    elif any(area in title_lower for area in ['samoa', 'aua', 'swains', 'american samoa']):\n",
    "        return 'American Samoa'\n",
    "    \n",
    "    # Mariana Archipelago keywords\n",
    "    elif any(area in title_lower for area in ['guam', 'mariana', 'saipan', 'tinian', 'rota']):\n",
    "        return 'Mariana Archipelago'\n",
    "    \n",
    "    # Pacific Remote Island Areas (PRIA)\n",
    "    elif any(area in title_lower for area in ['wake', 'baker', 'howland', 'jarvis', 'palmyra', 'kingman', 'johnstonpfkobia', 'jarvisisland']):\n",
    "        return 'Pacific Remote Island Areas'\n",
    "    \n",
    "    # Pacific-wide (catch-all for broad Pacific studies)\n",
    "    elif 'pacific' in title_lower:\n",
    "        return 'Pacific-wide'\n",
    "    \n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def clean_creators(creators):\n",
    "    \"\"\"Format creator names from API response.\"\"\"\n",
    "    if not creators:\n",
    "        return \"\"\n",
    "    names = []\n",
    "    for creator in creators:\n",
    "        first = creator.get('firstName', '').strip()\n",
    "        last = creator.get('lastName', '').strip()\n",
    "        if first or last:\n",
    "            names.append(f\"{first} {last}\".strip())\n",
    "    return \"; \".join(names)\n",
    "\n",
    "# Test the functions\n",
    "print(\"‚úì Helper functions defined\")\n",
    "print(f\"  - extract_year: Extracts 4-digit years from dates\")\n",
    "print(f\"  - assign_region: Classifies publications by geographic region\")\n",
    "print(f\"  - clean_creators: Formats author names\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27daef75",
   "metadata": {},
   "source": [
    "## Step 3: Clean and Transform Publication Data\n",
    "\n",
    "Define helper functions to extract year, assign regions, and standardize the publication metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_items(base_url, headers, batch_size=100):\n",
    "    \"\"\"\n",
    "    Fetch all items from Zotero API with pagination support.\n",
    "    \n",
    "    Args:\n",
    "        base_url: Zotero API endpoint URL\n",
    "        headers: Request headers with API key\n",
    "        batch_size: Items per request (max 100)\n",
    "    \n",
    "    Returns:\n",
    "        List of all items from the collection\n",
    "    \"\"\"\n",
    "    all_items = []\n",
    "    start = 0\n",
    "    \n",
    "    while True:\n",
    "        params = {\"format\": \"json\", \"limit\": batch_size, \"start\": start}\n",
    "        print(f\"Fetching items {start} to {start + batch_size}...\")\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            items = response.json()\n",
    "            \n",
    "            if not items:  # No more items\n",
    "                break\n",
    "            \n",
    "            all_items.extend(items)\n",
    "            start += batch_size\n",
    "            \n",
    "            # Respect rate limits\n",
    "            if 'Backoff' in response.headers:\n",
    "                import time\n",
    "                backoff_seconds = int(response.headers['Backoff'])\n",
    "                print(f\"Rate limited. Waiting {backoff_seconds} seconds...\")\n",
    "                time.sleep(backoff_seconds)\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Error fetching data: {e}\")\n",
    "            break\n",
    "    \n",
    "    return all_items\n",
    "\n",
    "# Fetch all publications\n",
    "print(\"üîÑ Fetching publications from Zotero...\")\n",
    "all_items = fetch_all_items(BASE_URL, HEADERS)\n",
    "print(f\"‚úì Fetched {len(all_items)} publications\")\n",
    "\n",
    "# Save raw JSON for reference\n",
    "with open(\"pifsc_arp_publications_raw.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_items, f, indent=4)\n",
    "print(\"‚úì Raw data saved to 'pifsc_arp_publications_raw.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a388387",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Publications from Zotero API\n",
    "\n",
    "This function fetches all publications from your Zotero collection, handling pagination automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c176cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zotero API Credentials\n",
    "GROUP_ID = \"UPDATEGROUPID\"\n",
    "COLLECTION_KEY = \"VD8Z582Z\" # default if pulling all publications from group id\n",
    "API_KEY = \"UPDATEWITHAPIKEY\"  #  Consider using environment variables for security\n",
    "BASE_URL = f\"https://api.zotero.org/groups/{GROUP_ID}/collections/{COLLECTION_KEY}/items\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Zotero-API-Key\": API_KEY,\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "print(f\"‚úì Zotero API configured for collection: {COLLECTION_KEY}\")\n",
    "print(f\"‚úì Base URL: {BASE_URL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47a4dc",
   "metadata": {},
   "source": [
    "## Step 1: Zotero API Configuration\n",
    "\n",
    "Update the variables below with your Zotero credentials. Obtain your API key from: https://www.zotero.org/settings/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Verify working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "# If needed, change to your working directory:\n",
    "# os.chdir('C:/Users/YOUR_USER/Desktop/')  # Uncomment and modify as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99740f",
   "metadata": {},
   "source": [
    "# Zotero Publications Data Pipeline for GitHub Pages\n",
    "\n",
    "This notebook fetches publications from a Zotero collection, cleans and enriches the data with region information, and exports it as YAML for rendering on GitHub Pages via Jekyll.\n",
    "\n",
    "**Workflow:**\n",
    "1. Connect to Zotero API and fetch publications\n",
    "2. Clean and standardize publication metadata\n",
    "3. Assign regions based on title keywords\n",
    "4. Export as YAML for `_data/filtered_pifsc_publications.yml` in your GitHub repo\n",
    "5. The Jekyll template will load and render the data in the publications table\n",
    "\n",
    "**Prerequisites:**\n",
    "- Zotero API key (obtain from https://www.zotero.org/settings/keys)\n",
    "- Group ID and Collection Key from your Zotero account\n",
    "- Working directory set up for file output"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

